{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![image](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/opengeos/HyperCoast/blob/main/docs/examples/moe_vae_acdom.ipynb)\n",
    "\n",
    "## Mixture of Experts Variational Autoencoder (MoE-VAE) for aCDOM440\n",
    "\n",
    "This example demonstrates how to use the Mixture of Experts Variational Autoencoder (MoE-VAE) to predict the Absorption Coefficient of Colored Dissolved Organic Matter at 440 nm (aCDOM440) using PACE data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install \"hypercoast[all]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypercoast import download_file\n",
    "from hypercoast.emit_utils.plot_and_save import plot_results_with_density\n",
    "from hypercoast.moe_vae import (\n",
    "    load_real_data_Robust,\n",
    "    load_real_test_Robust,\n",
    "    calculate_metrics,\n",
    "    plot_results,\n",
    "    save_results_to_excel,\n",
    "    save_results_from_excel_for_test,\n",
    "    preprocess_pace_data_Robust,\n",
    "    infer_and_visualize_single_model_Robust,\n",
    "    npy_to_tif,\n",
    "    MoE_VAE,\n",
    "    train,\n",
    "    evaluate,\n",
    ")\n",
    "import hypercoast.moe_vae.preprocess as preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://github.com/opengeos/datasets/releases/download/hypercoast/pace_moe_data.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_file(url, quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_path = \"./data/PACE_OCI.20240929T185124.L2.OC_AOP.V3_0.nc\"\n",
    "pace_rgb_path = \"./data/snapshot-2024-08-10T00_00_00Z.tif\"\n",
    "wavelength_filepath = \"./data/pace_wavelengths.csv\"\n",
    "# === Dataset paths ===\n",
    "excel_path_train = \"./data/Gloria_updated_07242025.xlsx\"\n",
    "test_files = [\n",
    "    \"./data/GOA_insitu_data_07242025updated.xlsx\",\n",
    "]\n",
    "base_save_dir = \"./test\"\n",
    "save_dir = os.path.join(base_save_dir, \"aCDOM440\")\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set PACE wavelengths for aCDOM440\n",
    "\n",
    "The wavelength selection for aCDOM440 is different from chl-a, focusing on 150 bands from 400-720nm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_PACE = pd.read_csv(wavelength_filepath)[\"wavelength\"].tolist()\n",
    "selected_bands = wv_PACE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read RGB image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(pace_rgb_path) as ds:\n",
    "    R, G, B = ds.read(1), ds.read(2), ds.read(3)\n",
    "    extent = [ds.bounds.left, ds.bounds.right, ds.bounds.bottom, ds.bounds.top]\n",
    "    rgb_image = np.stack((R, G, B), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training data\n",
    "\n",
    "Using robust scaling for aCDOM440 prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    train_real_dl,\n",
    "    test_real_dl,\n",
    "    input_dim,\n",
    "    output_dim,\n",
    "    train_ids,\n",
    "    test_ids,\n",
    "    scalers_Rrs_real,\n",
    "    scalers_dict,\n",
    ") = load_real_data_Robust(\n",
    "    excel_path=excel_path_train,\n",
    "    selected_bands=selected_bands,\n",
    "    target_parameter=\"aCDOM440\",\n",
    ")\n",
    "\n",
    "# Save scalers for later use\n",
    "torch.save(scalers_dict, os.path.join(save_dir, \"scaler.pt\"))\n",
    "with open(os.path.join(save_dir, \"scalers_Rrs_real.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(scalers_Rrs_real, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dls, test_ids_list, test_dates_list = [], [], []\n",
    "for file in test_files:\n",
    "    dl, _, _, ids, dates = load_real_test_Robust(\n",
    "        excel_path=file,\n",
    "        selected_bands=selected_bands,\n",
    "        scaler_Rrs=scalers_Rrs_real,\n",
    "        scalers_dict=scalers_dict,\n",
    "        target_parameter=\"aCDOM440\",\n",
    "    )\n",
    "    test_dls.append(dl)\n",
    "    test_ids_list.append(ids)\n",
    "    test_dates_list.append(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load PACE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader, Rrs, mask, latitude, longitude = preprocess_pace_data_Robust(\n",
    "    nc_path=nc_path,\n",
    "    scaler_Rrs=scalers_Rrs_real,\n",
    "    use_diff=False,\n",
    "    full_band_wavelengths=np.array(selected_bands),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize model\n",
    "\n",
    "The model architecture for aCDOM440 uses larger hidden dimensions compared to chl-a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MoE_VAE(\n",
    "    input_dim=input_dim,\n",
    "    output_dim=output_dim,\n",
    "    latent_dim=32,\n",
    "    encoder_hidden_dims=[256, 128, 64],\n",
    "    decoder_hidden_dims=[64, 128, 256],\n",
    "    activation=\"leakyrelu\",\n",
    "    use_norm=\"layer\",\n",
    "    use_dropout=False,\n",
    "    use_softplus_output=False,\n",
    "    num_experts=4,\n",
    "    k=2,\n",
    "    noisy_gating=True,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "train_log = train(\n",
    "    model,\n",
    "    train_real_dl,\n",
    "    device,\n",
    "    epochs=400,\n",
    "    optimizer=optimizer,\n",
    "    save_dir=save_dir,\n",
    ")\n",
    "best_train_loss = train_log[\"best_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to use an existing trained model, you can load it directly using the line below\n",
    "# and skip the training code above.\n",
    "import sys\n",
    "\n",
    "pretrained_model_url = (\n",
    "    \"https://github.com/opengeos/datasets/releases/download/hypercoast/pace_models.zip\"\n",
    ")\n",
    "download_file(pretrained_model_url, quiet=True)\n",
    "\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"pace_models/aCDOM440/best_model_minloss.pth\",\n",
    "        map_location=device,\n",
    "        weights_only=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Register the preprocess module under the short name for pickle compatibility\n",
    "sys.modules[\"preprocess\"] = preprocess\n",
    "\n",
    "with open(\"pace_models/aCDOM440/scalers_Rrs_real.pkl\", \"rb\") as f:\n",
    "    scalers_Rrs_real = pickle.load(f)\n",
    "\n",
    "# robust + log scaler (pt)\n",
    "scaler_pt_path = \"pace_models/aCDOM440/scaler.pt\"\n",
    "TSS_scalers_dict = torch.load(scaler_pt_path, map_location=device, weights_only=False)\n",
    "robust_scaler = TSS_scalers_dict[\"robust\"]\n",
    "log_scaler = TSS_scalers_dict[\"log\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, actuals = evaluate(\n",
    "    model, test_real_dl, device, TSS_scalers_dict=scalers_dict\n",
    ")\n",
    "epsilon, beta, rmse, rmsle, mape, bias, mae = calculate_metrics(predictions, actuals)\n",
    "test_loss = mae\n",
    "\n",
    "save_results_to_excel(\n",
    "    test_ids, actuals, predictions, os.path.join(save_dir, \"test_results.xlsx\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results_with_density(\n",
    "    predictions, actuals, save_dir, mode=\"test_results\", xlim=(-4, 2), ylim=(-4, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/user-attachments/assets/eec95d64-5d25-4f55-b889-d4e56543577f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(predictions, actuals, save_dir, mode=\"test_results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/user-attachments/assets/c726e9d9-4f6f-4ca4-bcde-172da71e3800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dl, ids, dates, path in zip(test_dls, test_ids_list, test_dates_list, test_files):\n",
    "    preds, acts = evaluate(model, dl, device, TSS_scalers_dict=scalers_dict)\n",
    "    save_results_from_excel_for_test(preds, acts, ids, dates, path, save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Output = infer_and_visualize_single_model_Robust(\n",
    "    model=model,\n",
    "    test_loader=test_loader,\n",
    "    Rrs=Rrs,\n",
    "    mask=mask,\n",
    "    latitude=latitude,\n",
    "    longitude=longitude,\n",
    "    save_folder=save_dir,\n",
    "    extent=extent,\n",
    "    rgb_image=rgb_image,\n",
    "    structure_name=\"aCDOM440\",\n",
    "    TSS_scalers_dict=scalers_dict,\n",
    "    vmin=0,\n",
    "    vmax=5,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"âœ… Finished training, train loss: {best_train_loss:.4f}, test loss: {test_loss:.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/user-attachments/assets/404060a0-9ed5-45c9-a704-465b2d603216)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save as GeoTIFF (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tif_path = os.path.join(save_dir, \"aCDOM440.tif\")\n",
    "\n",
    "npy_to_tif(npy_input=Output, out_tif=tif_path, resolution_m=1000)\n",
    "\n",
    "with rasterio.open(tif_path) as src:\n",
    "    img = src.read(1)\n",
    "    transform = src.transform\n",
    "    bounds = src.bounds\n",
    "img_masked = np.where(img < 0, np.nan, img)\n",
    "extent = [bounds.left, bounds.right, bounds.bottom, bounds.top]\n",
    "plt.figure(figsize=(8, 6))\n",
    "im = plt.imshow(img_masked, cmap=\"jet\", vmin=0, vmax=5, extent=extent, origin=\"upper\")\n",
    "plt.colorbar(im, label=\"aCDOM440\")\n",
    "plt.title(\"aCDOM440\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/user-attachments/assets/6b303aa8-a007-4b43-8aff-d52a0be2ed66)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
